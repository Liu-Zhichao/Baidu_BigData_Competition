{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liuzhichao/Documents/GitHub/Baidu_BigData_Competition/code\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/Users/liuzhichao/Documents/GitHub/Baidu_BigData_Competition/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liuzhichao/Documents/GitHub/Baidu_BigData_Competition\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/data_processed/region_names.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        region_names = line.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(region_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "# train, validation, test split\n",
    "def data_split(dataset, args):\n",
    "    indices = np.arange(0, len(dataset))\n",
    "    # no validation set\n",
    "    if args.val_num <= 0:\n",
    "        # leave-one out test set\n",
    "        train_num = len(dataset) - 1\n",
    "        train_indices = indices[:train_num]\n",
    "        test_indices = indices[-1:]\n",
    "        return Subset(dataset, train_indices), None, Subset(dataset, test_indices)\n",
    "    else:\n",
    "        train_num = len(dataset) - args.val_num - 1\n",
    "\n",
    "        train_indices = indices[:train_num]\n",
    "        valid_indices = indices[train_num:train_num + args.val_num]\n",
    "        test_indices = indices[-1:]\n",
    "        return Subset(dataset, train_indices), \\\n",
    "                Subset(dataset, valid_indices), Subset(dataset, test_indices)\n",
    "\n",
    "\n",
    "class BaseDataset(object):\n",
    "    \"\"\"BaseDataset\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"getitem\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"len\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Subset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"getitem\"\"\"\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"len\"\"\"\n",
    "        return len(self.indices)\n",
    "\n",
    "\n",
    "class BaseDataset(object):\n",
    "    \"\"\"BaseDataset\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"getitem\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"len\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Subset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"getitem\"\"\"\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"len\"\"\"\n",
    "        return len(self.indices)\n",
    "\n",
    "\n",
    "class InfectDataset(BaseDataset):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.input_file = self.args.input_file\n",
    "        self.label_file = self.args.label_file\n",
    "        self.region_names_file = self.args.region_names_file\n",
    "\n",
    "        self.city_num = self.args.city_num\n",
    "        self.feat_dim = self.args.feat_dim\n",
    "        self.n_pred = self.args.n_pred\n",
    "        self.n_his = self.args.n_his\n",
    "\n",
    "        self.data = self.process()\n",
    "\n",
    "    def process(self):\n",
    "        X = pd.read_csv(self.input_file)\n",
    "        X = X.fillna(0.0)\n",
    "        Y = pd.read_csv(self.label_file)\n",
    "\n",
    "        with open(self.region_names_file, 'r') as f:\n",
    "            for line in f:\n",
    "                region_names = line.strip().split()\n",
    "\n",
    "        # scaling (why scaling here?)\n",
    "        SCALE = 1000\n",
    "        for name in region_names:\n",
    "            X[name] = X[[name]].apply(lambda x: x / SCALE)\n",
    "            Y[name] = Y[[name]].apply(lambda x: x / SCALE)\n",
    "\n",
    "        print(\"region migration: \", X.head())\n",
    "        print(\"infect: \", Y.head())\n",
    "\n",
    "        X = X.drop(columns=['date'])\n",
    "        Y = Y.drop(columns=['date'])\n",
    "        # total number of training examples\n",
    "        date_num = len(Y)\n",
    "        # maybe for future use\n",
    "        train_num = date_num - self.n_pred\n",
    "\n",
    "        df = pd.DataFrame(columns=X.columns)\n",
    "        # (?, n_his, city_num, node_feat_dim)\n",
    "        for i in range(date_num - self.n_his - self.n_pred + 1):\n",
    "            df = df.append(X[i:(i + self.n_his)])\n",
    "            df = df.append(Y[(i + self.n_his):(i + self.n_his + self.n_pred)])\n",
    "\n",
    "        # for testing\n",
    "        df = df.append(X[-self.n_his:])\n",
    "        df = df.append(Y[-self.n_pred:])  # unused, for padding\n",
    "\n",
    "        data = df.values.reshape(-1, self.n_his + self.n_pred, self.city_num, 1)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return np.expand_dims(self.data[idx], axis=0)\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--train_all'], dest='train_all', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--city_num', type=int, default=5)\n",
    "parser.add_argument('--feat_dim', type=int, default=1)\n",
    "parser.add_argument('--n_his', type=int, default=10)\n",
    "parser.add_argument('--n_pred', type=int, default=10)\n",
    "parser.add_argument('--batch_size', type=int, default=10)\n",
    "parser.add_argument('--epochs', type=int, default=100)\n",
    "parser.add_argument('--save', type=int, default=10)\n",
    "parser.add_argument('--Ks', type=int, default=3)  #equal to num_layers\n",
    "parser.add_argument('--Kt', type=int, default=3)\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "parser.add_argument('--keep_prob', type=float, default=1.0)\n",
    "parser.add_argument('--opt', type=str, default='ADAM')\n",
    "parser.add_argument('--inf_mode', type=str, default='sep')\n",
    "parser.add_argument('--input_file', type=str, default='dataset/data_processed/migration.csv')\n",
    "parser.add_argument('--label_file', type=str, default='dataset/data_processed/infection.csv')\n",
    "parser.add_argument('--adj_mat_file', type=str, default='dataset/data_processed/adj_matrix.npy')\n",
    "parser.add_argument('--output_path', type=str, default='./outputs/')\n",
    "parser.add_argument('--val_num', type=str, default=0)\n",
    "parser.add_argument('--test_num', type=str, default=1)\n",
    "parser.add_argument('--use_cuda', action='store_true')\n",
    "parser.add_argument('--train_all', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--city_num CITY_NUM] [--feat_dim FEAT_DIM]\n",
      "                             [--n_his N_HIS] [--n_pred N_PRED]\n",
      "                             [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--save SAVE] [--Ks KS] [--Kt KT] [--lr LR]\n",
      "                             [--keep_prob KEEP_PROB] [--opt OPT]\n",
      "                             [--inf_mode INF_MODE] [--input_file INPUT_FILE]\n",
      "                             [--label_file LABEL_FILE]\n",
      "                             [--adj_mat_file ADJ_MAT_FILE]\n",
      "                             [--output_path OUTPUT_PATH] [--val_num VAL_NUM]\n",
      "                             [--test_num TEST_NUM] [--use_cuda] [--train_all]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/liuzhichao/Library/Jupyter/runtime/kernel-7482beaa-96ab-44b5-98d5-999fcc5d98a3.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
